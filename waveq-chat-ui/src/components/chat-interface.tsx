'use client'

import { useState, useRef, useEffect } from 'react'
import { Button } from '@/components/ui/button'
import { Input } from '@/components/ui/input'
import { Textarea } from '@/components/ui/textarea'
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card'
import { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar'
import { Upload, Send, FileAudio, MessageCircle, Bot, User } from 'lucide-react'
import Link from 'next/link'
import { AudioVisualization } from './audio-visualization'
import { CodeCanvas } from './code-canvas'

interface ChatMessage {
  id: string
  text: string
  sender: 'user' | 'assistant'
  timestamp: Date
  audioFile?: string
  downloadUrl?: string
  originalAudioFile?: File
  showVisualization?: boolean
  status?: 'uploaded' | 'processed' | 'error'
  code?: string
}

interface ChatInterfaceProps {
  theme?: 'dark' | 'light'
}

export function ChatInterface({ theme = 'light' }: ChatInterfaceProps) {
  const [messages, setMessages] = useState<ChatMessage[]>([])
  
  // Initialize messages after component mounts to avoid hydration issues
  useEffect(() => {
    // Try to load saved chat history from localStorage
    const savedMessages = localStorage.getItem('WAVEQ_CHAT_HISTORY')
    
    if (savedMessages) {
      try {
        const parsedMessages = JSON.parse(savedMessages)
        // Convert timestamp strings back to Date objects
        const messagesWithDates = parsedMessages.map((msg: any) => ({
          ...msg,
          timestamp: new Date(msg.timestamp)
        }))
        setMessages(messagesWithDates)
      } catch (error) {
        console.error('Error loading chat history:', error)
        // Fallback to default welcome message
        setMessages([
          {
            id: '1',
            text: `×©×œ×•×! ×× ×™ Gemini AI, ××•××—×” ×‘×¢×™×‘×•×“ ××•×“×™×•. 

ğŸµ **××™×š ×œ×”×©×ª××© ×‘××¢×¨×›×ª:**

**ğŸ“ ×œ×¢×™×‘×•×“ ××•×“×™×•:**
1. **×”×¢×œ×” ×§×•×‘×¥ ××•×“×™×•** - ×œ×—×¥ ×¢×œ ×›×¤×ª×•×¨ ×”×”×¢×œ××”
2. **×›×ª×•×‘ ×”×•×¨××•×ª ×¢×™×‘×•×“** ×‘××•×ª×” ×”×•×“×¢×”:
   â€¢ "×”×’×‘×¨ ××ª ×”×¢×•×¦××” ×‘-50%"
   â€¢ "×—×ª×•×š ××ª ×”-10 ×©× ×™×•×ª ×”×¨××©×•× ×•×ª" 
   â€¢ "×”×•×¡×£ ×‘××¡ ×•×©×¤×¨ ××™×›×•×ª"
   â€¢ "×”×¤×—×ª ×¨×¢×© ×•× ×¨××œ"
3. **×©×œ×—** - ×”××¢×¨×›×ª ×ª×¢×‘×“ ×•×ª×—×–×™×¨ ×§×•×‘×¥ ××¢×•×‘×“

**ğŸ’¬ ×œ×©××œ×•×ª ×›×œ×œ×™×•×ª:**
â€¢ ×©××œ ×¢×œ ×˜×›× ×™×§×•×ª ×¢×™×‘×•×“ ××•×“×™×•
â€¢ ×§×‘×œ ×¢×¦×•×ª ×œ××™×§×¡ ×•×××¡×˜×¨×™× ×’
â€¢ ×œ××“ ×¢×œ ×›×œ×™ ×¢×™×‘×•×“ ×©×•× ×™×

**ğŸ“ ×§×•×‘×¦×™ ×™×™×¦×•×:**
×›×œ ×”×§×‘×¦×™× ×”××¢×•×‘×“×™× × ×©××¨×™× ×‘×“×£ ×”×™×™×¦×•××™×

××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×š ×”×™×•×? ğŸ§`,
            sender: 'assistant',
            timestamp: new Date()
          }
        ])
      }
    } else {
      // Default welcome message
      setMessages([
        {
          id: '1',
          text: `×©×œ×•×! ×× ×™ Gemini AI, ××•××—×” ×‘×¢×™×‘×•×“ ××•×“×™×•. 

ğŸµ **××™×š ×œ×”×©×ª××© ×‘××¢×¨×›×ª:**

**ğŸ“ ×œ×¢×™×‘×•×“ ××•×“×™×•:**
1. **×”×¢×œ×” ×§×•×‘×¥ ××•×“×™×•** - ×œ×—×¥ ×¢×œ ×›×¤×ª×•×¨ ×”×”×¢×œ××”
2. **×›×ª×•×‘ ×”×•×¨××•×ª ×¢×™×‘×•×“** ×‘××•×ª×” ×”×•×“×¢×”:
   â€¢ "×”×’×‘×¨ ××ª ×”×¢×•×¦××” ×‘-50%"
   â€¢ "×—×ª×•×š ××ª ×”-10 ×©× ×™×•×ª ×”×¨××©×•× ×•×ª" 
   â€¢ "×”×•×¡×£ ×‘××¡ ×•×©×¤×¨ ××™×›×•×ª"
   â€¢ "×”×¤×—×ª ×¨×¢×© ×•× ×¨××œ"
3. **×©×œ×—** - ×”××¢×¨×›×ª ×ª×¢×‘×“ ×•×ª×—×–×™×¨ ×§×•×‘×¥ ××¢×•×‘×“

**ğŸ’¬ ×œ×©××œ×•×ª ×›×œ×œ×™×•×ª:**
â€¢ ×©××œ ×¢×œ ×˜×›× ×™×§×•×ª ×¢×™×‘×•×“ ××•×“×™×•
â€¢ ×§×‘×œ ×¢×¦×•×ª ×œ××™×§×¡ ×•×××¡×˜×¨×™× ×’
â€¢ ×œ××“ ×¢×œ ×›×œ×™ ×¢×™×‘×•×“ ×©×•× ×™×

**ğŸ“ ×§×•×‘×¦×™ ×™×™×¦×•×:**
×›×œ ×”×§×‘×¦×™× ×”××¢×•×‘×“×™× × ×©××¨×™× ×‘×“×£ ×”×™×™×¦×•××™×

××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×š ×”×™×•×? ğŸ§`,
          sender: 'assistant',
          timestamp: new Date()
        }
      ])
    }
  }, [])
  const [inputText, setInputText] = useState('')
  const [audioFile, setAudioFile] = useState<File | null>(null)
  const [isLoading, setIsLoading] = useState(false)
  const [status, setStatus] = useState<'idle' | 'success' | 'error'>('idle')
  const [statusMessage, setStatusMessage] = useState('')

  const fileInputRef = useRef<HTMLInputElement>(null)

  // Function to analyze audio file and provide insights
  const analyzeAudioFile = async (file: File) => {
    const fileSize = formatFileSize(file.size)
    const fileType = file.type || 'audio/mp3'
    const fileName = file.name
    
    // Create audio context to analyze the file
    const arrayBuffer = await file.arrayBuffer()
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
    
    try {
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)
      const duration = audioBuffer.duration
      const sampleRate = audioBuffer.sampleRate
      const numberOfChannels = audioBuffer.numberOfChannels
      
      // Analyze audio characteristics
      const channelData = audioBuffer.getChannelData(0) // Get first channel
      const length = channelData.length
      
      // Calculate RMS (Root Mean Square) for volume analysis
      let rms = 0
      let peak = 0
      let zeroCrossings = 0
      
      for (let i = 0; i < length; i++) {
        const sample = Math.abs(channelData[i])
        rms += sample * sample
        if (sample > peak) peak = sample
        if (i > 0 && ((channelData[i] >= 0) !== (channelData[i-1] >= 0))) {
          zeroCrossings++
        }
      }
      rms = Math.sqrt(rms / length)
      
      // Determine quality based on sample rate and bit depth
      let quality = '×‘×™× ×•× ×™×ª'
      if (sampleRate >= 48000) quality = '×’×‘×•×”×” ×××•×“'
      else if (sampleRate >= 44100) quality = '×’×‘×•×”×”'
      else if (sampleRate >= 22050) quality = '×‘×™× ×•× ×™×ª'
      else quality = '× ××•×›×”'
      
      // Generate detailed summary based on analysis
      let summary = ''
      
      // Volume analysis
      if (rms < 0.05) summary = 'ğŸ”‡ ×”×§×•×‘×¥ ×©×§×˜ ×××•×“ - ×“×•×¨×© ×”×’×‘×¨×ª ×¢×•×¦××” ××©××¢×•×ª×™×ª'
      else if (rms < 0.1) summary = 'ğŸ”ˆ ×”×§×•×‘×¥ ×©×§×˜ ×™×—×¡×™×ª - ××•××œ×¥ ×”×’×‘×¨×ª ×¢×•×¦××”'
      else if (rms < 0.3) summary = 'ğŸ”‰ ×”×§×•×‘×¥ ×‘×¢×•×¦××” × ××•×›×”-×‘×™× ×•× ×™×ª - ×™×™×ª×›×Ÿ ×©×¦×¨×™×š ×”×’×‘×¨×” ×§×œ×”'
      else if (rms < 0.7) summary = 'ğŸ”Š ×”×§×•×‘×¥ ×××•×–×Ÿ ×”×™×˜×‘ ××‘×—×™× ×ª ×¢×•×¦××” - ××™×›×•×ª ×˜×•×‘×”'
      else if (rms < 0.9) summary = 'ğŸ”Š ×”×§×•×‘×¥ ×¨× - ×™×™×ª×›×Ÿ ×©×¦×¨×™×š ×”×¤×—×ª×” ×§×œ×”'
      else summary = 'ğŸ”Š ×”×§×•×‘×¥ ×¨× ×××•×“ - ×“×•×¨×© ×”×¤×—×ª×ª ×¢×•×¦××”'
      
      // Peak analysis
      if (peak > 0.98) summary += '\nâš ï¸ ×™×© ×©×™××™× ×’×‘×•×”×™× ×××•×“ ×©×¢×œ×•×œ×™× ×œ×’×¨×•× ×œ×¢×™×•×•×ª ×—××•×¨'
      else if (peak > 0.95) summary += '\nâš ï¸ ×™×© ×©×™××™× ×’×‘×•×”×™× ×©×¢×œ×•×œ×™× ×œ×’×¨×•× ×œ×¢×™×•×•×ª'
      else if (peak > 0.9) summary += '\nâš ï¸ ×™×© ×©×™××™× ×’×‘×•×”×™× - ××•××œ×¥ ×”×’×‘×œ×”'
      else summary += '\nâœ… ××™×Ÿ ×©×™××™× ×‘×¢×™×™×ª×™×™× - ×¨××ª ×¢×•×¦××” ×‘×˜×•×—×”'
      
      // Channel analysis
      if (numberOfChannels === 1) summary += '\nğŸ“» ×§×•×‘×¥ ××•× ×• (×¢×¨×•×¥ ××—×“) - ××™×›×•×ª ×‘×¡×™×¡×™×ª'
      else summary += '\nğŸ§ ×§×•×‘×¥ ×¡×˜×¨×™××• (×©× ×™ ×¢×¨×•×¦×™×) - ××™×›×•×ª ××§×¦×•×¢×™×ª'
      
      // Sample rate analysis
      if (sampleRate >= 48000) summary += '\nğŸ¯ ×ª×“×¨ ×“×’×™××” ×’×‘×•×” ×××•×“ - ××™×›×•×ª ××§×¦×•×¢×™×ª'
      else if (sampleRate >= 44100) summary += '\nğŸ¯ ×ª×“×¨ ×“×’×™××” ×¡×˜× ×“×¨×˜×™ - ××™×›×•×ª ×˜×•×‘×”'
      else if (sampleRate >= 22050) summary += '\nğŸ¯ ×ª×“×¨ ×“×’×™××” × ××•×š - ××™×›×•×ª ×‘×¡×™×¡×™×ª'
      else summary += '\nğŸ¯ ×ª×“×¨ ×“×’×™××” × ××•×š ×××•×“ - ××™×›×•×ª ×™×¨×•×“×”'
      
      // Generate detailed recommendations
      let recommendations = ''
      
      // Volume recommendations
      if (rms < 0.05) recommendations += 'ğŸ”Š **×”×’×‘×¨×ª ×¢×•×¦××” ××©××¢×•×ª×™×ª** - ×”×§×•×‘×¥ ×©×§×˜ ××“×™\n'
      else if (rms < 0.1) recommendations += 'ğŸ”Š **×”×’×‘×¨×ª ×¢×•×¦××”** - ×”×§×•×‘×¥ ×©×§×˜ ×™×—×¡×™×ª\n'
      else if (rms > 0.9) recommendations += 'ğŸ”Š **×”×¤×—×ª×ª ×¢×•×¦××”** - ×”×§×•×‘×¥ ×¨× ××“×™\n'
      
      // Peak recommendations
      if (peak > 0.98) recommendations += 'âš ï¸ **×”×’×‘×œ×ª ×©×™××™× ×“×—×•×¤×”** - ×× ×™×¢×ª ×¢×™×•×•×ª\n'
      else if (peak > 0.95) recommendations += 'âš ï¸ **×”×’×‘×œ×ª ×©×™××™×** - ×× ×™×¢×ª ×¢×™×•×•×ª\n'
      else if (peak > 0.9) recommendations += 'âš ï¸ **×”×’×‘×œ×ª ×©×™××™× ×§×œ×”** - ×©×™×¤×•×¨ ××™×›×•×ª\n'
      
      // Quality recommendations
      if (sampleRate < 22050) recommendations += 'ğŸ¯ **×©×“×¨×•×’ ××™×›×•×ª ×“×—×•×£** - ×ª×“×¨ ×“×’×™××” × ××•×š ××“×™\n'
      else if (sampleRate < 44100) recommendations += 'ğŸ¯ **×©×“×¨×•×’ ××™×›×•×ª** - ×ª×“×¨ ×“×’×™××” × ××•×š\n'
      
      // Channel recommendations
      if (numberOfChannels === 1) recommendations += 'ğŸ“» **×”××¨×” ×œ×¡×˜×¨×™××•** - ×©×™×¤×•×¨ ××™×›×•×ª (××•×¤×¦×™×•× ×œ×™)\n'
      
      // General recommendations
      recommendations += 'ğŸµ **×¢×™×‘×•×“ ×›×œ×œ×™ ××•××œ×¥:**\n'
      recommendations += 'â€¢ × ×¨××•×œ ×¢×•×¦××” (Normalize)\n'
      recommendations += 'â€¢ ×”×¤×—×ª×ª ×¨×¢×© (Noise Reduction)\n'
      recommendations += 'â€¢ ×©×™×¤×•×¨ ××™×–×•×Ÿ ×ª×“×¨×™× (EQ)\n'
      
      if (!recommendations.includes('ğŸ”Š') && !recommendations.includes('âš ï¸') && !recommendations.includes('ğŸ¯')) {
        recommendations = 'âœ… **×”×§×•×‘×¥ ×‘××™×›×•×ª ×˜×•×‘×” ×××•×“!**\n'
        recommendations += 'â€¢ ××™×Ÿ ×¦×•×¨×š ×‘×¢×™×‘×•×“ ×“×—×•×£\n'
        recommendations += 'â€¢ × ×™×ª×Ÿ ×œ×©×¤×¨ ××¢×˜ ×¢× ×¢×™×‘×•×“ ×¢×“×™×Ÿ'
      }
      
      // Generate smart quick actions based on analysis
      let quickActions = ''
      
      // Priority actions based on analysis
      if (rms < 0.05) quickActions += 'ğŸš¨ **×¤×¢×•×œ×•×ª ×“×—×•×¤×•×ª:**\n'
      else if (rms < 0.1) quickActions += 'ğŸ”Š **×¤×¢×•×œ×•×ª ××•××œ×¦×•×ª:**\n'
      else quickActions += 'ğŸµ **×¤×¢×•×œ×•×ª ×œ×©×™×¤×•×¨:**\n'
      
      // Volume actions
      if (rms < 0.05) quickActions += 'â€¢ `×”×’×‘×¨ ××ª ×”×¢×•×¦××” ×‘-80%`\n'
      else if (rms < 0.1) quickActions += 'â€¢ `×”×’×‘×¨ ××ª ×”×¢×•×¦××” ×‘-50%`\n'
      else if (rms > 0.9) quickActions += 'â€¢ `×”×¤×—×ª ××ª ×”×¢×•×¦××” ×‘-30%`\n'
      
      // Peak actions
      if (peak > 0.98) quickActions += 'â€¢ `×”×’×‘×œ ×©×™××™× ×“×—×•×£ ×•× ×¨××œ`\n'
      else if (peak > 0.95) quickActions += 'â€¢ `×”×’×‘×œ ×©×™××™× ×•× ×¨××œ`\n'
      else if (peak > 0.9) quickActions += 'â€¢ `×”×’×‘×œ ×©×™××™× ×§×œ`\n'
      
      // Quality actions
      if (sampleRate < 22050) quickActions += 'â€¢ `×©×“×¨×’ ××™×›×•×ª ×“×—×•×£ ×œ-44.1kHz`\n'
      else if (sampleRate < 44100) quickActions += 'â€¢ `×©×“×¨×’ ××™×›×•×ª ×œ-48kHz`\n'
      
      // General improvement actions
      quickActions += 'â€¢ `×”×¤×—×ª ×¨×¢×© ×•× ×¨××œ ×¢×•×¦××”`\n'
      quickActions += 'â€¢ `×©×¤×¨ ××™×–×•×Ÿ ×ª×“×¨×™× (EQ)`\n'
      quickActions += 'â€¢ `×”×•×¡×£ ×‘××¡ ×•×©×¤×¨ ××™×›×•×ª ×›×œ×œ×™×ª`\n'
      
      return {
        summary,
        fileSize,
        fileType: fileType.split('/')[1]?.toUpperCase() || 'MP3',
        quality,
        duration: formatDuration(duration),
        recommendations,
        quickActions
      }
      
    } catch (error) {
      // Fallback analysis if audio decoding fails
      return {
        summary: '×œ× × ×™×ª×Ÿ ×œ× ×ª×— ××ª ×”×§×•×‘×¥ - ×™×™×ª×›×Ÿ ×©×”×•× ×¤×’×•× ××• ×‘×¤×•×¨××˜ ×œ× × ×ª××š',
        fileSize,
        fileType: fileType.split('/')[1]?.toUpperCase() || 'MP3',
        quality: '×œ× ×™×“×•×¢',
        duration: '×œ× ×™×“×•×¢',
        recommendations: 'â€¢ ×‘×“×•×§ ×©×”×§×•×‘×¥ ×ª×§×™×Ÿ\nâ€¢ × ×¡×” ×§×•×‘×¥ ×‘×¤×•×¨××˜ ××—×¨',
        quickActions: 'â€¢ `×”××¨ ×œ×¤×•×¨××˜ MP3`\nâ€¢ `×‘×“×•×§ ×ª×§×™× ×•×ª ×”×§×•×‘×¥`'
      }
    } finally {
      audioContext.close()
    }
  }

  // Helper function to format file size
  const formatFileSize = (bytes: number) => {
    if (bytes === 0) return '0 Bytes'
    const k = 1024
    const sizes = ['Bytes', 'KB', 'MB', 'GB']
    const i = Math.floor(Math.log(bytes) / Math.log(k))
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i]
  }

  // Helper function to format duration
  const formatDuration = (seconds: number) => {
    const minutes = Math.floor(seconds / 60)
    const remainingSeconds = Math.floor(seconds % 60)
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`
  }

  // Helper function to save messages to localStorage (without File objects)
  const saveMessagesToStorage = (messagesToSave: ChatMessage[]) => {
    const messagesForStorage = messagesToSave.map(msg => ({
      ...msg,
      originalAudioFile: undefined // Remove File objects before saving
    }))
    localStorage.setItem('WAVEQ_CHAT_HISTORY', JSON.stringify(messagesForStorage))
  }

  const handleRunCode = async (code: string) => {
    try {
      await fetch('/api/run-code', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ code })
      })
    } catch (error) {
      console.error('Error running code:', error)
    }
  }

  const handleDownloadCode = (code: string) => {
    const blob = new Blob([code], { type: 'text/plain' })
    const url = URL.createObjectURL(blob)
    const a = document.createElement('a')
    a.href = url
    a.download = 'code.txt'
    a.click()
    URL.revokeObjectURL(url)
  }

  const handleSendMessage = async () => {
    if (!inputText.trim() && !audioFile) return

    // Check if this is an audio processing request
    const isAudioProcessing = audioFile && inputText.trim()
    const isAudioFileOnly = audioFile && !inputText.trim()
    
  const newMessage: ChatMessage = {
      id: Date.now().toString(),
      text: isAudioProcessing
        ? `×¢×™×‘×•×“ ××•×“×™×•: ${audioFile.name} - ${inputText}`
        : inputText || `×”×¢×œ××ª ×§×•×‘×¥ ××•×“×™×•: ${audioFile?.name}`,
      sender: 'user',
      timestamp: new Date(),
      audioFile: audioFile?.name,
      status: audioFile ? 'uploaded' : undefined
    }

    const updatedMessages = [...messages, newMessage]
    setMessages(updatedMessages)
    
    // Save updated messages to localStorage
    saveMessagesToStorage(updatedMessages)
    
    const currentInput = inputText
    const currentAudioFile = audioFile
    setInputText('')
    setAudioFile(null)
    setIsLoading(true)

    try {
      // Get API key from localStorage
      const apiKey = localStorage.getItem('GEMINI_API_KEY')
      
      if (!apiKey) {
        // Show error message in chat with settings button
        const errorResponse: ChatMessage = {
          id: (Date.now() + 1).toString(),
          text: '××¤×ª×— API ×—×¡×¨. ×× × ×”×’×“×¨ ××ª ××¤×ª×— ×”-API ×©×œ Gemini AI ×›×“×™ ×œ×”×ª×—×™×œ ×œ×©×•×—×—. ×œ×—×¥ ×¢×œ ×›×¤×ª×•×¨ ×”×”×’×“×¨×•×ª ×œ××¢×œ×”.',
          sender: 'assistant',
          timestamp: new Date()
        }
        const updatedMessagesWithError = [...messages, errorResponse]
        setMessages(updatedMessagesWithError)
        saveMessagesToStorage(updatedMessagesWithError)
        setIsLoading(false)
        return
      }

      if (isAudioFileOnly) {
        // Handle audio file upload without instructions - analyze the file automatically
        
        // Show loading message first
        const loadingMessage: ChatMessage = {
          id: (Date.now() + 1).toString(),
          text: `ğŸ” **×× ×ª×— ××ª ×”×§×•×‘×¥ "${currentAudioFile!.name}"...**

×”××¢×¨×›×ª ×‘×•×“×§×ª ××ª ×”×××¤×™×™× ×™× ×”×˜×›× ×™×™× ×©×œ ×”×§×•×‘×¥ ×•××›×™× ×” ×”××œ×¦×•×ª ××•×ª×××•×ª ××™×©×™×ª...`,
          sender: 'assistant',
          timestamp: new Date()
        }
        const updatedMessagesWithLoading = [...updatedMessages, loadingMessage]
        setMessages(updatedMessagesWithLoading)
        saveMessagesToStorage(updatedMessagesWithLoading)
        
                 try {
           // Analyze the audio file automatically
           const audioAnalysis = await analyzeAudioFile(currentAudioFile!)
           
           // Update uploaded file with analysis data
           const existingUploads = localStorage.getItem('WAVEQ_UPLOADED_FILES')
           if (existingUploads) {
             try {
               let uploads = JSON.parse(existingUploads)
               const fileIndex = uploads.findIndex((f: any) => f.name === currentAudioFile!.name)
               if (fileIndex !== -1) {
                 uploads[fileIndex].duration = audioAnalysis.duration
                 uploads[fileIndex].quality = audioAnalysis.quality
                 uploads[fileIndex].status = 'processed'
                 localStorage.setItem('WAVEQ_UPLOADED_FILES', JSON.stringify(uploads))
               }
             } catch (error) {
               console.error('Error updating uploaded file:', error)
             }
           }
           
           const aiResponse: ChatMessage = {
             id: (Date.now() + 1).toString(),
             text: `ğŸµ **× ×™×ª×•×— ××•×˜×•××˜×™ ×©×œ ×”×§×•×‘×¥: "${currentAudioFile!.name}"**

ğŸ“Š **××” ×”××¢×¨×›×ª ×”×‘×™× ×” ××”×§×•×‘×¥:**
${audioAnalysis.summary}

ğŸ” **×¤×¨×˜×™× ×˜×›× ×™×™×:**
â€¢ **×’×•×“×œ ×§×•×‘×¥:** ${audioAnalysis.fileSize}
â€¢ **×¡×•×’ ×§×•×‘×¥:** ${audioAnalysis.fileType}
â€¢ **××™×›×•×ª:** ${audioAnalysis.quality}
â€¢ **××©×š:** ${audioAnalysis.duration}

ğŸ’¡ **×”××œ×¦×•×ª ×œ×¢×™×‘×•×“ ××•×˜×•××˜×™:**
${audioAnalysis.recommendations}

ğŸš€ **×¤×¢×•×œ×•×ª ××”×™×¨×•×ª ××•××œ×¦×•×ª:**
${audioAnalysis.quickActions}

ğŸ“Š **×•×™×–×•××œ×™×–×¦×™×” ×’×¨×¤×™×ª ××ª×¦×•×’×ª ×”×§×•×‘×¥ ××˜×”** â¬‡ï¸

ğŸ“ **××™×š ×œ×¢×‘×“ ××ª ×”×§×•×‘×¥:**
1. ×”×¢×œ×” ×©×•×‘ ××ª ×”×§×•×‘×¥ ğŸ“
2. ×›×ª×•×‘ ×”×•×¨××•×ª ×¢×™×‘×•×“ ×¡×¤×¦×™×¤×™×•×ª
3. ×©×œ×— - ×•×× ×™ ××¢×‘×“ ×¢×‘×•×¨×š!

××” ×ª×¨×¦×” ×œ×¢×©×•×ª ×¢× ×”×§×•×‘×¥ ×”×–×”? ğŸ§`,
             sender: 'assistant',
             timestamp: new Date(),
             originalAudioFile: currentAudioFile!,
             showVisualization: true
           }
          const updatedMessagesWithAI = [...updatedMessages, aiResponse]
          setMessages(updatedMessagesWithAI)
          saveMessagesToStorage(updatedMessagesWithAI)
        } catch (error) {
          // Fallback to basic message if analysis fails
          const aiResponse: ChatMessage = {
            id: (Date.now() + 1).toString(),
            text: `ğŸµ **×§×•×‘×¥ ××•×“×™×• ×”×ª×§×‘×œ ×‘×”×¦×œ×—×”!**

×× ×™ ×¨×•××” ×©×”×¢×œ×ª ××ª ×”×§×•×‘×¥ "${currentAudioFile!.name}". 

ğŸ’¡ **×›×“×™ ×©××•×›×œ ×œ×¢×‘×“ ××ª ×”×§×•×‘×¥ ×¢×‘×•×¨×š, ×× × ×”×•×¡×£ ×”×•×¨××•×ª ×¢×™×‘×•×“:**

ğŸ”§ **×“×•×’×××•×ª ×œ×¢×™×‘×•×“:**
â€¢ "×”×’×‘×¨ ××ª ×”×¢×•×¦××” ×‘-50%"
â€¢ "×—×ª×•×š ××ª ×”-10 ×”×©× ×™×•×ª ×”×¨××©×•× ×•×ª"
â€¢ "×”×•×¡×£ ×‘××¡ ×—×–×§ ×•×ª×›×œ×™× ××¡×š"
â€¢ "×”×¤×—×ª ×¨×¢×© ×•×©×¤×¨ ××™×›×•×ª"
â€¢ "×”×¤×•×š ××ª ×”×§×•×œ (reverse)"
â€¢ "×”×•×¡×£ echo"
â€¢ "× ×¨××œ ××ª ×”×¢×•×¦××”"

ğŸ“ **××™×š ×œ×¢×©×•×ª ×–××ª:**
1. ×”×¢×œ×” ×©×•×‘ ××ª ×”×§×•×‘×¥ ğŸ“
2. ×›×ª×•×‘ ×”×•×¨××•×ª ×¢×™×‘×•×“ ×‘×¨×•×¨×•×ª
3. ×©×œ×— - ×•×× ×™ ××¢×‘×“ ××ª ×”×§×•×‘×¥ ×¢×‘×•×¨×š!

××” ×ª×¨×¦×” ×œ×¢×©×•×ª ×¢× ×”×§×•×‘×¥ ×”×–×”? ğŸ§

ğŸš€ **×¤×¢×•×œ×•×ª ××”×™×¨×•×ª - ×œ×—×¥ ×›×“×™ ×œ×”×¢×ª×™×§:**
â€¢ \`×”×’×‘×¨ ××ª ×”×¢×•×¦××” ×‘-30%\`
â€¢ \`×”×¤×—×ª ×¨×¢×© ×•× ×¨××œ\`
â€¢ \`×—×ª×•×š ××ª ×”-5 ×©× ×™×•×ª ×”×¨××©×•× ×•×ª\`
â€¢ \`×”×•×¡×£ ×‘××¡ ×•×©×¤×¨ ××™×›×•×ª\``,
            sender: 'assistant',
            timestamp: new Date()
          }
          const updatedMessagesWithAI = [...updatedMessages, aiResponse]
          setMessages(updatedMessagesWithAI)
          saveMessagesToStorage(updatedMessagesWithAI)
        }
      } else if (isAudioProcessing) {
        // Upload audio and instructions then poll for processing
        const formData = new FormData()
        formData.append('audio', currentAudioFile!)
        formData.append('text', currentInput)

        const uploadResponse = await fetch('/api/chat/audio', {
          method: 'POST',
          body: formData
        })

        if (!uploadResponse.ok) {
          const errorData = await uploadResponse.json()
          const errorResponse: ChatMessage = {
            id: (Date.now() + 2).toString(),
            text: `âŒ ×©×’×™××” ×‘×”×¢×œ××ª ×”××•×“×™×•: ${errorData.error || '×©×’×™××” ×œ× ×™×“×•×¢×”'}`,
            sender: 'assistant',
            timestamp: new Date()
          }
          const updatedMessagesWithError = [...updatedMessages, errorResponse]
          setMessages(updatedMessagesWithError)
          saveMessagesToStorage(updatedMessagesWithError)
          return
        }

        const { request_id } = await uploadResponse.json()

        // Poll for processing completion
        let processingStatus = 'pending'
        while (processingStatus !== 'completed' && processingStatus !== 'error') {
          await new Promise(resolve => setTimeout(resolve, 2000))
          const statusResp = await fetch(`/api/audio/status/${request_id}`)
          if (statusResp.ok) {
            const statusData = await statusResp.json()
            processingStatus = statusData.status
          } else {
            processingStatus = 'error'
          }
        }

        if (processingStatus === 'completed') {
          const downloadResp = await fetch(`/api/audio/download/${request_id}`)
          if (downloadResp.ok) {
            const processedAudioBlob = await downloadResp.blob()
            const processedFileName = `processed_${currentAudioFile!.name}`
            const downloadUrl = URL.createObjectURL(processedAudioBlob)

            // Update uploaded file status
            const existingUploads = localStorage.getItem('WAVEQ_UPLOADED_FILES')
            if (existingUploads) {
              try {
                const uploads = JSON.parse(existingUploads)
                const fileIndex = uploads.findIndex((f: any) => f.name === currentAudioFile!.name)
                if (fileIndex !== -1) {
                  uploads[fileIndex].status = 'processed'
                  uploads[fileIndex].downloadUrl = downloadUrl
                  uploads[fileIndex].operations = [currentInput]
                  localStorage.setItem('WAVEQ_UPLOADED_FILES', JSON.stringify(uploads))
                }
              } catch (err) {
                console.error('Error updating uploaded file:', err)
              }
            }

            // Save to exports list
            const exportedFile = {
              id: Date.now().toString(),
              name: processedFileName,
              originalName: currentAudioFile!.name,
              processedAt: new Date(),
              size: processedAudioBlob.size,
              downloadUrl: downloadUrl,
              operations: [currentInput]
            }

            const existingExports = localStorage.getItem('WAVEQ_EXPORTED_FILES')
            let exports = []
            if (existingExports) {
              try {
                exports = JSON.parse(existingExports)
              } catch (error) {
                console.error('Error parsing exported files:', error)
              }
            }
            exports.unshift(exportedFile)
            localStorage.setItem('WAVEQ_EXPORTED_FILES', JSON.stringify(exports))

            const aiResponse: ChatMessage = {
              id: (Date.now() + 2).toString(),
              text: `âœ… ×”×§×•×‘×¥ ×¢×•×‘×“ ×‘×”×¦×œ×—×”!\n\nğŸ“ ×”×§×•×‘×¥ × ×©××¨ ×‘×§×•×‘×¦×™ ×”×™×™×¦×•× ×•××•×›×Ÿ ×œ×”×•×¨×“×”!`,
              sender: 'assistant',
              timestamp: new Date(),
              audioFile: processedFileName,
              downloadUrl: downloadUrl,
              status: 'processed'
            }

            const updatedMessagesWithAI = [...updatedMessages, aiResponse]
            setMessages(updatedMessagesWithAI)
            saveMessagesToStorage(updatedMessagesWithAI)
          } else {
            const errorResponse: ChatMessage = {
              id: (Date.now() + 2).toString(),
              text: 'âŒ ×©×’×™××” ×‘×”×•×¨×“×ª ×”×§×•×‘×¥ ×”××¢×•×‘×“',
              sender: 'assistant',
              timestamp: new Date()
            }
            const updatedMessagesWithError = [...updatedMessages, errorResponse]
            setMessages(updatedMessagesWithError)
            saveMessagesToStorage(updatedMessagesWithError)
          }
        } else {
          const errorResponse: ChatMessage = {
            id: (Date.now() + 2).toString(),
            text: 'âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”××•×“×™×•',
            sender: 'assistant',
            timestamp: new Date()
          }
          const updatedMessagesWithError = [...updatedMessages, errorResponse]
          setMessages(updatedMessagesWithError)
          saveMessagesToStorage(updatedMessagesWithError)
        }
      } else {
        // Call regular Gemini Chat API - for general audio questions
        const response = await fetch('/api/chat', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'x-gemini-api-key': apiKey
          },
          body: JSON.stringify({
            message: currentInput || `×”×¢×œ××ª ×§×•×‘×¥ ××•×“×™×•: ${currentAudioFile?.name}`,
            audioFile: currentAudioFile?.name,
            chatHistory: messages
          })
        })

      const data = await response.json()

      if (data.success) {
        const aiResponse: ChatMessage = {
          id: (Date.now() + 1).toString(),
          text: data.message,
          sender: 'assistant',
          timestamp: new Date()
        }
        const updatedMessagesWithAI = [...updatedMessages, aiResponse]
        setMessages(updatedMessagesWithAI)
        saveMessagesToStorage(updatedMessagesWithAI)
      } else {
        // Fallback response
        const fallbackResponse: ChatMessage = {
          id: (Date.now() + 1).toString(),
          text: data.fallback || '×× ×™ ××¦×˜×¢×¨, ×™×© ×‘×¢×™×” ×‘×ª×§×©×•×¨×ª ×¢× Gemini AI. ×× × ×‘×“×•×§ ××ª ××¤×ª×— ×”-API ×‘×“×£ ×”×”×’×“×¨×•×ª.',
          sender: 'assistant',
          timestamp: new Date()
        }
        const updatedMessagesWithFallback = [...updatedMessages, fallbackResponse]
        setMessages(updatedMessagesWithFallback)
        saveMessagesToStorage(updatedMessagesWithFallback)
        
        // Show specific error if available
        if (data.error) {
          console.error('Chat API Error:', data.error)
        }
      }
    }
  } catch (error) {
      console.error('Chat API Error:', error)
      // Error fallback
      const errorResponse: ChatMessage = {
        id: (Date.now() + 1).toString(),
        text: '×× ×™ ××¦×˜×¢×¨, ×™×© ×‘×¢×™×” ×‘×ª×§×©×•×¨×ª. ×× × × ×¡×” ×©×•×‘ ××• ×‘×“×•×§ ××ª ×”×—×™×‘×•×¨ ×œ××™× ×˜×¨× ×˜.',
        sender: 'assistant',
        timestamp: new Date()
      }
      const updatedMessagesWithGeneralError = [...messages, errorResponse]
      setMessages(updatedMessagesWithGeneralError)
      saveMessagesToStorage(updatedMessagesWithGeneralError)
    } finally {
      setIsLoading(false)
    }
  }

  const handleFileSelect = (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0]
    if (file && file.type.startsWith('audio/')) {
      setAudioFile(file)
      
      // Save uploaded file to localStorage
      const uploadedFile = {
        id: Date.now().toString(),
        name: file.name,
        originalName: file.name,
        uploadedAt: new Date(),
        size: file.size,
        type: file.type,
        status: 'uploaded' as const,
        fileType: file.type,
        duration: undefined,
        quality: undefined,
        operations: [],
        downloadUrl: undefined
      }
      
      // Get existing uploads
      const existingUploads = localStorage.getItem('WAVEQ_UPLOADED_FILES')
      let uploads = []
      if (existingUploads) {
        try {
          uploads = JSON.parse(existingUploads)
        } catch (error) {
          console.error('Error parsing uploaded files:', error)
        }
      }
      
      // Add new upload
      uploads.unshift(uploadedFile)
      localStorage.setItem('WAVEQ_UPLOADED_FILES', JSON.stringify(uploads))
    }
  }

  // Function to detect language and return text direction
  const detectLanguage = (text: string): 'rtl' | 'ltr' => {
    // Hebrew characters range
    const hebrewRegex = /[\u0590-\u05FF\uFB1D-\uFB4F]/
    // Arabic characters range
    const arabicRegex = /[\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF]/
    
    if (hebrewRegex.test(text) || arabicRegex.test(text)) {
      return 'rtl'
    }
    return 'ltr'
  }

  const handleKeyPress = (event: React.KeyboardEvent) => {
    if (event.key === 'Enter' && !event.shiftKey) {
      event.preventDefault()
      handleSendMessage()
    }
  }

  return (
    <div className="max-w-4xl mx-auto">
      <Card className={`shadow-xl border-0 ${theme === 'dark' ? 'bg-gray-900' : 'bg-white'}`}>
        
        
                 <CardContent className="p-0">
           {/* Chat Messages */}
           <div className={`h-[calc(100vh-400px)] overflow-y-auto p-4 space-y-3 ${
             theme === 'dark' ? 'bg-gray-900' : 'bg-gray-50'
           }`}>
            {messages.map((message) => (
              <div
                key={message.id}
                className={`flex gap-3 ${
                  message.sender === 'user' ? 'flex-row-reverse' : 'flex-row'
                }`}
              >
                <Avatar className="w-8 h-8">
                  {message.sender === 'user' ? (
                    <AvatarFallback className="bg-blue-500">
                      <User className="w-4 h-4 text-white" />
                    </AvatarFallback>
                  ) : (
                    <AvatarFallback className="bg-purple-500">
                      <Bot className="w-4 h-4 text-white" />
                    </AvatarFallback>
                  )}
                </Avatar>
                
                                 <div className={`max-w-[70%] ${
                   message.sender === 'user' ? 'text-right' : 'text-left'
                 }`}>
                   <div className={`inline-block p-4 rounded-2xl shadow-sm ${
                     message.sender === 'user'
                       ? 'bg-gradient-to-r from-blue-500 to-blue-600 text-white'
                       : theme === 'dark' 
                         ? 'bg-gray-800 text-gray-100 border border-gray-700'
                         : 'bg-white text-gray-800 border border-gray-200'
                   }`}>
                    {message.audioFile && (
                      <div className="flex items-center gap-2 mb-3 text-sm opacity-80 bg-black/10 rounded-lg p-2">
                        <FileAudio className="w-4 h-4" />
                        {message.audioFile}
                        {message.status && (
                          <span
                            className={`ml-2 px-2 py-0.5 rounded-full text-xs font-medium ${
                              message.status === 'uploaded'
                                ? 'bg-blue-100 text-blue-800'
                                : message.status === 'processed'
                                  ? 'bg-green-100 text-green-800'
                                  : 'bg-red-100 text-red-800'
                            }`}
                          >
                            {message.status === 'uploaded'
                              ? '×”×•×¢×œ×”'
                              : message.status === 'processed'
                                ? '×¢×•×‘×“'
                                : '×©×’×™××”'}
                          </span>
                        )}
                      </div>
                    )}
                     <p
                       className="whitespace-pre-wrap leading-relaxed"
                       style={{
                         textAlign: detectLanguage(message.text) === 'rtl' ? 'right' : 'left',
                         direction: detectLanguage(message.text)
                       }}
                     >
                       {message.text}
                     </p>
                     {message.code && (
                       <div className="mt-3">
                         <CodeCanvas code={message.code} theme={theme} />
                         <div className="flex gap-2 mt-2">
                           <Button size="sm" onClick={() => handleRunCode(message.code!)}>
                             Run
                           </Button>
                           <Button
                             size="sm"
                             variant="secondary"
                             onClick={() => handleDownloadCode(message.code!)}
                           >
                             Download
                           </Button>
                         </div>
                       </div>
                     )}
                     {message.downloadUrl && (
                       <div className="mt-3">
                         <a
                           href={message.downloadUrl}
                           download={message.audioFile}
                           className={`inline-flex items-center gap-2 px-4 py-2 rounded-lg text-sm font-medium transition-colors ${
                             theme === 'dark'
                               ? 'bg-green-600 hover:bg-green-700 text-white'
                               : 'bg-green-500 hover:bg-green-600 text-white'
                           }`}
                         >
                           <FileAudio className="w-4 h-4" />
                           ×”×•×¨×“ ×§×•×‘×¥ ××¢×•×‘×“
                         </a>
                       </div>
                     )}
                   </div>
                   
                   {/* Audio Visualization */}
                   {message.showVisualization && message.originalAudioFile && (
                     <div className="mt-4">
                       <AudioVisualization 
                         audioFile={message.originalAudioFile} 
                         theme={theme}
                       />
                     </div>
                   )}
                   
                   <p className={`text-xs mt-2 ${
                     detectLanguage(message.text) === 'rtl' ? 'text-right' : 'text-left'
                   } ${
                     theme === 'dark' ? 'text-gray-400' : 'text-gray-500'
                   }`}>
                     {message.timestamp.toLocaleTimeString('he-IL')}
                   </p>
                 </div>
              </div>
            ))}
            
                         {isLoading && (
               <div className="flex gap-3">
                 <Avatar className="w-8 h-8">
                   <AvatarFallback className="bg-purple-500">
                     <Bot className="w-4 h-4 text-white" />
                   </AvatarFallback>
                 </Avatar>
                 <div className={`p-4 rounded-2xl shadow-sm ${
                   theme === 'dark' 
                     ? 'bg-gray-800 text-gray-100 border border-gray-700' 
                     : 'bg-white text-gray-800 border border-gray-200'
                 }`}>
                   <div className="flex items-center gap-3">
                     <div className="flex space-x-2">
                       <div className="w-3 h-3 bg-purple-500 rounded-full animate-bounce"></div>
                       <div className="w-3 h-3 bg-blue-500 rounded-full animate-bounce" style={{animationDelay: '0.1s'}}></div>
                       <div className="w-3 h-3 bg-purple-500 rounded-full animate-bounce" style={{animationDelay: '0.2s'}}></div>
                     </div>
                                           <span 
                        className={`text-sm font-medium ${
                          theme === 'dark' ? 'text-gray-300' : 'text-gray-600'
                        }`}
                        style={{ 
                          textAlign: 'right',
                          direction: 'rtl'
                        }}
                      >
                        Gemini ×—×•×©×‘...
                      </span>
                   </div>
                 </div>
               </div>
             )}
          </div>

                           

                           {/* Message Input */}
                 <div className={`border-t p-4 ${
                   theme === 'dark' 
                     ? 'bg-gray-900 border-gray-700' 
                     : 'bg-white border-gray-200'
                 }`}>
                                       <div className="flex gap-3">
                      <div className="flex-1 flex gap-2">
                        <Textarea
                          value={inputText}
                          onChange={(e) => setInputText(e.target.value)}
                          onKeyPress={handleKeyPress}
                          placeholder={audioFile 
                            ? "ğŸ’¡ ×›×ª×•×‘ ×”×•×¨××•×ª ×¢×™×‘×•×“: '×”×’×‘×¨ ××ª ×”×¢×•×¦××” ×‘-30%', '×”×¤×—×ª ×¨×¢×©', '×—×ª×•×š ××ª ×”×”×ª×—×œ×”'..."
                            : "ğŸ’¬ ×©××œ ×©××œ×” ×¢×œ ×¢×™×‘×•×“ ××•×“×™×• ××• ×”×¢×œ×” ×§×•×‘×¥ + ×”×•×¨××•×ª ×¢×™×‘×•×“..."
                          }
                          className={`flex-1 resize-none rounded-xl border-2 focus:border-purple-500 transition-colors ${
                            theme === 'dark' 
                              ? 'bg-gray-800 border-gray-600 text-white placeholder-gray-400' 
                              : 'bg-gray-50 border-gray-200 text-gray-900 placeholder-gray-500'
                          }`}
                          style={{ 
                            textAlign: inputText ? (detectLanguage(inputText) === 'rtl' ? 'right' : 'left') : 'right',
                            direction: inputText ? detectLanguage(inputText) : 'rtl'
                          }}
                          rows={2}
                        />
                        
                                                    {/* File Upload Button */}
                            <div className="flex flex-col gap-1">
                              <Button
                                variant="outline"
                                onClick={() => fileInputRef.current?.click()}
                                className={`w-12 h-12 p-0 border-2 hover:border-purple-500 transition-all duration-200 ${
                                  theme === 'dark' 
                                    ? 'bg-gray-800 border-gray-600 hover:bg-gray-700 text-white' 
                                    : 'bg-white border-gray-200 hover:bg-gray-50 text-gray-900'
                                }`}
                                title="×”×¢×œ××ª ×§×•×‘×¥ ××•×“×™×•"
                              >
                                <Upload className="w-5 h-5" />
                              </Button>


                          
                          {/* File Input */}
                          <input
                            ref={fileInputRef}
                            type="file"
                            accept="audio/*"
                            onChange={handleFileSelect}
                            className="hidden"
                          />
                          
                          {/* Selected File Display */}
                          {audioFile && (
                            <div className={`px-3 py-2 rounded-lg text-xs text-center ${
                              theme === 'dark' 
                                ? 'bg-green-900/20 border border-green-700 text-green-300' 
                                : 'bg-green-50 border border-green-200 text-green-800'
                            }`}>
                              <FileAudio className="w-4 h-4 mx-auto mb-1" />
                              <div className="truncate max-w-20">
                                {audioFile.name}
                              </div>
                            </div>
                          )}
                        </div>
                      </div>
                                                                  <Button
                         onClick={handleSendMessage}
                         disabled={(!inputText.trim() && !audioFile) || isLoading}
                         className="w-14 h-14 p-0 bg-gradient-to-r from-purple-600 to-blue-600 hover:from-purple-700 hover:to-blue-700 text-white font-medium rounded-xl shadow-lg hover:shadow-xl transition-all duration-200 flex items-center justify-center"
                         title="×©×œ×— ×”×•×“×¢×”"
                       >
                         <Send className="w-6 h-6" />
                       </Button>
                   </div>
                 </div>
        </CardContent>
      </Card>


    </div>
  )
}
